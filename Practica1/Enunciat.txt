The goal is to implement a Python  Distributed DataFrame (Dask Dataframes)  inspired in the Dask python library.
The idea is to execute operations in Dataframes residing in remote nodes.  You must implement
four solutions using different technologies: XMLRPC, gRPC, Redis, and RabbitMQ.

Implement  a Master/Worker cluster architecture where a frontend accesses the different nodes.
The Master node should support a simple API to add or remove nodes from the cluster.
You should also be able to offer a subset of the Dask DataFrame API  for dealing with CSV data.
Support operations like: read_csv,  apply, columns, groupby, head, isin, items, max, min.
You are encouraged to copy code from Internet and Dask if necessary.

Theoretical tasks:

    Provide diagrams explaining the solutions you have implemented. Show plots validating the execution of distributed tasks compared to the same execution in a single machine.
    Compare the architectures that you designed using direct or indirect communication middleware. You can even propose solutions that combine different middleware services (like gRPC and Redis).
    Read this paper: https://arxiv.org/abs/1702.04024 and describe the distributed architecture and communication middleware used in this solution,


Deliver the code compressed in zip format including a PDF file answering the theoretical questions.

Implement three architectures: direct communication, hybrid (direct+indirect), and indirect communication.
To pass this task you need at least to implement direct and hybrid architecture with xmlrpc and redis and deliver the theoretical tasks.
Implementing indirect communication and grpc/rabbit will be need to obtain excellent degrees.